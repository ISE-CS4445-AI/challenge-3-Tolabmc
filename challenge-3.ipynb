{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTTUuzCyzRqG"
      },
      "source": [
        "# Challenge 3 - Advanced Classification and Evaluation Metrics\n",
        "\n",
        "Welcome to challenge #3! You know the drill by now i.e., the MCQ section and the code challenge section.\n",
        "\n",
        "Good luck! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROAjx16L5x5Y"
      },
      "source": [
        "## Section 1: Multiple Choice Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRALy2NEz0AS"
      },
      "source": [
        "### Q1. Which statement is **true** regarding **precision** in a multi-class classification context? (1 point)\n",
        "\n",
        "**Options**:  \n",
        "1. Precision is the fraction of actual positives that were predicted positive.  \n",
        "2. Precision is the fraction of predicted positives that are actual positives.  \n",
        "3. Precision is the fraction of negative predictions that are correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFtBxSL40CG9",
        "outputId": "49e0c805-cd5f-4d4b-be20-2cf551c8bc86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q1: Which statement is **true** regarding **precision** in a multi-class classification context? (1 point)\n",
            "Answer: Precision is the fraction of predicted positives that are actual positives\n"
          ]
        }
      ],
      "source": [
        "def answer_q1():\n",
        "    \"\"\"\n",
        "    Q1: Which statement is **true** regarding **precision** in a multi-class classification context? (1 point)\n",
        "    \"\"\"\n",
        "\n",
        "    options = {\n",
        "        1: \"Precision is the fraction of actual positives that were predicted positive\",\n",
        "        2: \"Precision is the fraction of predicted positives that are actual positives\",\n",
        "        3: \"Precision is the fraction of negative predictions that are correct\"\n",
        "    }\n",
        "\n",
        "    # TODO: return the correct option number\n",
        "    return options[2]\n",
        "\n",
        "print(f'Q1: Which statement is **true** regarding **precision** in a multi-class classification context? (1 point)\\nAnswer: {answer_q1()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9BRj9Qv0v9o"
      },
      "source": [
        "### Q2. Which statement correctly describes the confusion matrix in a multi-class setting? (1 point)\n",
        "**Options:**\n",
        "1. It’s only valid for binary classification, not used for multi-class.\n",
        "2. It’s an NxN array for N classes, comparing predicted vs. actual class labels.\n",
        "3. It only shows the total correct vs. total incorrect predictions, no class breakdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFto7n3ny7UA",
        "outputId": "2025056d-b701-4a72-89b4-7a459c2828b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q2: Which statement correctly describes the confusion matrix in a multi-class setting?\n",
            "Answer: It’s an NxN array for N classes, comparing predicted vs. actual class labels\n"
          ]
        }
      ],
      "source": [
        "def answer_q2():\n",
        "    \"\"\"\n",
        "    Q2: Which statement correctly describes the confusion matrix in a multi-class setting? (1 point)\n",
        "    \"\"\"\n",
        "\n",
        "    options = {\n",
        "        1: \"It’s only valid for binary classification, not used for multi-class\",\n",
        "        2: \"It’s an NxN array for N classes, comparing predicted vs. actual class labels\",\n",
        "        3: \"It only shows the total correct vs. total incorrect predictions, no class breakdown\"\n",
        "    }\n",
        "\n",
        "    # TODO: return the correct option number\n",
        "    return options[2]\n",
        "\n",
        "print(f'Q2: Which statement correctly describes the confusion matrix in a multi-class setting?\\nAnswer: {answer_q2()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAYgSO7Z2FTd"
      },
      "source": [
        "### Q3. Which classifier typically uses bagging plus random subsets of features to reduce variance? (1 point)\n",
        "**Options:**\n",
        "1. Decision Tree\n",
        "2. Random Forest\n",
        "3. Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5SAsK9C2Z8R",
        "outputId": "edd20aeb-bf1e-4fcf-fd84-17c8e39a92a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q3: Which classifier typically uses bagging plus random subsets of features to reduce variance?\n",
            "Answer: Random Forest\n"
          ]
        }
      ],
      "source": [
        "def answer_q3():\n",
        "    \"\"\"\n",
        "    Q3: Which classifier typically uses bagging plus random subsets of features to reduce variance? (1 point)\n",
        "    \"\"\"\n",
        "\n",
        "    options = {\n",
        "        1: \"Decision Tree\",\n",
        "        2: \"Random Forest\",\n",
        "        3: \"Naive Bayes\"\n",
        "    }\n",
        "\n",
        "    # TODO: return the correct option number\n",
        "    return options[2]\n",
        "\n",
        "print(f'Q3: Which classifier typically uses bagging plus random subsets of features to reduce variance?\\nAnswer: {answer_q3()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Q4. If we see a high recall but low precision for a certain class, what does that usually imply? (1 point)\n",
        "**Options:**\n",
        "1. The model rarely finds actual positives for that class.\n",
        "2. The model finds most actual positives (few false negatives), but also mislabels many negatives as that class (many false positives).\n",
        "3. The model completely fails to detect that class at all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q3: If we see a high recall but low precision for a certain class, what does that usually imply?\n",
            "Answer: The model finds most actual positives (few false negatives), but also mislabels many negatives as that class (many false positives)\n"
          ]
        }
      ],
      "source": [
        "def answer_q4():\n",
        "    \"\"\"\n",
        "    Q3: If we see a high recall but low precision for a certain class, what does that usually imply? (1 point)\n",
        "    \"\"\"\n",
        "\n",
        "    options = {\n",
        "        1: \"The model rarely finds actual positives for that class\",\n",
        "        2: \"The model finds most actual positives (few false negatives), but also mislabels many negatives as that class (many false positives)\",\n",
        "        3: \"The model completely fails to detect that class at all\"\n",
        "    }\n",
        "\n",
        "    # TODO: return the correct option number\n",
        "    return options[2]\n",
        "\n",
        "print(f'Q3: If we see a high recall but low precision for a certain class, what does that usually imply?\\nAnswer: {answer_q4()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2tw01le53fJ"
      },
      "source": [
        "---\n",
        "\n",
        "## Section 2: Code challenge (5 points)\n",
        "\n",
        "For this code challenge, you will work with the [UCI Car Evaluation dataset](https://www.kaggle.com/datasets/elikplim/car-evaluation-data-set). A summary of the dataset is as follows.\n",
        "\n",
        "### Features:\n",
        "- **buying**: Buying price of the car (vhigh, high, med, low)\n",
        "- **maint**: Price of the maintenance (vhigh, high, med, low)\n",
        "- **doors**: Number of doors (2, 3, 4, 5more)\n",
        "- **persons**: Capacity in terms of persons to carry (2, 4, more)\n",
        "- **lug_boot**: Size of the luggage boot (small, med, big)\n",
        "- **safety**: Estimated safety of the car (low, med, high)\n",
        "\n",
        "### Class Labels:\n",
        "- **unacc**: Unacceptable\n",
        "- **acc**: Acceptable\n",
        "- **good**: Good\n",
        "- **vgood**: Very Good\n",
        "\n",
        "To pass this section of the weekly challenge, uncomment/fill in code where necessary (marked with a 'TODO:' comment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Load & Encode Car Dataset (1 point)\n",
        "\n",
        "**Goals** for `load_and_encode_car_data()`\n",
        "1. Reads car.csv.\n",
        "2. Encodes 6 features (buying, maint, doors, persons, lug_boot, safety).\n",
        "    e.g. one-hot or custom mapping.\n",
        "3. Maps class -> integer: unacc=0, acc=1, good=2, vgood=3.\n",
        "4. Returns (X, y) as arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Cm3MG7iySn15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes: (1728, 15) (1728,)\n"
          ]
        }
      ],
      "source": [
        "def load_and_encode_car_data():\n",
        "    \"\"\"\n",
        "    1) read 'car.csv'\n",
        "    2) encode the 6 features to numeric or one-hot\n",
        "    3) map class to {0,1,2,3}\n",
        "    4) return X, y\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    data = pd.read_csv(\"car.csv\")\n",
        "    data =pd.get_dummies(data, columns=['buying','maint','doors', 'persons', 'lug_boot', 'safety'], drop_first=True)\n",
        "    \n",
        "    # mapping class\n",
        "    class_mapping = {'unacc':0, 'acc':1, 'good':2, 'vgood':3}\n",
        "    data['class'] = data['class'].map(class_mapping)\n",
        "\n",
        "    # X ,y as arrays\n",
        "    X = data.drop(columns=['class']).values  \n",
        "    y = data['class'].values\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# demonstration\n",
        "X, y = load_and_encode_car_data()\n",
        "print(\"Shapes:\", X.shape, y.shape)\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hry_mfD2St36"
      },
      "source": [
        "### 2. Train Baseline Model (1 point)\n",
        "\n",
        "**Goals** for `train_baseline_model(X, y)`:\n",
        "1. Split data (test_size=0.2, random_state=42).\n",
        "2. Use a simple classifier (logistic or naive_bayes, etc.).\n",
        "3. Return (model, X_test, y_test, y_pred)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "t6L9tk63SxuZ"
      },
      "outputs": [],
      "source": [
        "def train_classifier(X, y):\n",
        "    \"\"\"\n",
        "    1. split X,y\n",
        "    2. pick a classifier\n",
        "    3. fit & predict \n",
        "    4. return (model, X_test, y_test, y_pred)\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    X, y = load_and_encode_car_data()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    model = RandomForestClassifier\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    \n",
        "    return model, X_test, y_test, y_pred\n",
        "    \n",
        "    \n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Generate Confusion Matrix (1 point)\n",
        "\n",
        "**Goals**:\n",
        "1.  `generate_confmatrix(y_true, y_pred)` → returns an NxN confusion matrix array from scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_confmatrix(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Return confusion_matrix array (sklearn).\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return conf_matrix\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww-oRhCNS0_6"
      },
      "source": [
        "### 4. Compute F1 score (1 point)\n",
        "\n",
        "**Goals** for `manual_f1_for_class(y_true, y_pred, class_idx)`:\n",
        "1. Use scikit-learn to get precision, recall for that single class, e.g. by calling `precision_score(..., labels=[class_idx], average='macro')` or `average='binary'` approach.\n",
        "2. Then manually compute F1 using the formula (no direct scikit calls for F1).\n",
        "3. Return the F1 score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def manual_f1_for_class(y_true, y_pred, class_idx):\n",
        "    \"\"\"\n",
        "    1) use scikit to get precision, recall for 'class_idx' only\n",
        "    2) compute f1 score manually\n",
        "    return that float\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    precision = precision_score(y_true, y_pred, labels=[class_idx], average='macro')\n",
        "    recall = recall_score(y_true, y_pred, labels=[class_idx], average= 'macro')\n",
        "    if precision + recall != 0:\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        f1_score = 0.0\n",
        "\n",
        "    return f1_score\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaVV4aDxYEUH"
      },
      "source": [
        "### 5. Generate Classification Report (1 point)\n",
        "\n",
        "**Goals**\n",
        "\n",
        "1. Generate a classification report for your trained model and return the report (string value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute '_validate_params'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[79], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# optional demonstration\u001b[39;00m\n\u001b[1;32m     13\u001b[0m X, y \u001b[38;5;241m=\u001b[39m load_and_encode_car_data()\n\u001b[0;32m---> 14\u001b[0m model, X_te, y_te, y_pr \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerate confmatrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m cm \u001b[38;5;241m=\u001b[39m generate_confmatrix(y_te, y_pr)\n",
            "Cell \u001b[0;32mIn[76], line 12\u001b[0m, in \u001b[0;36mtrain_classifier\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, X_test, y_test, y_pred\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1382\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1377\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1378\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1379\u001b[0m )\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1382\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[1;32m   1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute '_validate_params'"
          ]
        }
      ],
      "source": [
        "def generate_classification_report(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    calls sklearn's classification_report\n",
        "    returns it\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    class_report= classification_report(y_true, y_pred)\n",
        "    return class_report\n",
        "    pass\n",
        "\n",
        "\n",
        "# optional demonstration\n",
        "X, y = load_and_encode_car_data()\n",
        "model, X_te, y_te, y_pr = train_classifier(X,y)\n",
        "print(\"Generate confmatrix:\")\n",
        "cm = generate_confmatrix(y_te, y_pr)\n",
        "print(cm)\n",
        "f1class0 = manual_f1_for_class(y_te, y_pr, class_idx=0)\n",
        "print(\"F1 for class 0 manually:\", f1class0)\n",
        "rep = generate_classification_report(y_te, y_pr)\n",
        "print(rep)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
